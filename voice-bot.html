<!DOCTYPE html>
<html lang="zh-HK">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>æ™ºèƒ½åŠ©æ‰‹ / AI Assistant / AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      background-color: #f5f5f5;
    }
    h1 {
      color: #2c3e50;
      text-align: center;
    }
    .chat-container {
      height: 60vh;
      overflow-y: auto;
      padding: 15px;
      background-color: white;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      margin-bottom: 20px;
    }
    .message-container {
      margin-bottom: 15px;
      display: flex;
      align-items: center;
    }
    .message {
      padding: 10px 15px;
      border-radius: 18px;
      max-width: 80%;
      word-wrap: break-word;
    }
    .user-container {
      justify-content: flex-end;
    }
    .user {
      background-color: #e1f5fe;
      border-bottom-right-radius: 5px;
      text-align: right;
    }
    .bot-container {
      justify-content: flex-start;
    }
    .bot {
      background-color: #f1f1f1;
      border-bottom-left-radius: 5px;
    }
    .input-area {
      display: flex;
      gap: 10px;
    }
    #message-input {
      flex-grow: 1;
      padding: 12px 15px;
      border: 1px solid #ddd;
      border-radius: 25px;
      font-size: 16px;
      outline: none;
    }
    button {
      background-color: #4285f4;
      color: white;
      border: none;
      border-radius: 25px;
      padding: 0 20px;
      cursor: pointer;
      font-size: 16px;
      transition: background-color 0.3s;
    }
    button:hover {
      background-color: #3367d6;
    }
    .speak-btn {
      background-color: transparent;
      color: #333;
      font-size: 20px;
      margin-left: 8px;
      padding: 0 10px;
    }
    .language-toggle {
      text-align: center;
      margin-bottom: 20px;
    }
    .toggle-btn {
      background-color: #f1f1f1;
      color: #333;
      margin: 0 5px;
      padding: 8px 15px;
      font-size: 14px;
    }
    .toggle-btn.active {
      background-color: #4285f4;
      color: white;
    }
    .mic-button {
      background-color: #4CAF50;
      transition: background-color 0.3s;
    }
    .mic-button.recording {
      background-color: #f44336;
      animation: pulse 1.5s infinite;
    }
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.1); }
      100% { transform: scale(1); }
    }
    .mic-indicator {
      width: 10px;
      height: 10px;
      border-radius: 50%;
      background-color: #ccc;
      display: inline-block;
      margin-right: 5px;
    }
    .mic-active {
      background-color: #f44336;
    }
    .footnote {
      text-align: center;
      font-size: 12px;
      color: #777;
      margin-top: 20px;
    }
    .status-message {
      color: #777;
      font-style: italic;
      text-align: center;
      margin: 10px 0;
    }
    .error {
      color: #d32f2f;
      font-weight: bold;
    }
    .controls {
      display: flex;
      justify-content: space-between;
      margin-bottom: 10px;
    }

    /* Configuration Panel Styles */
    .config-panel {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0, 0, 0, 0.5);
      display: none;
      justify-content: center;
      align-items: center;
      z-index: 1000;
    }
    .config-content {
      background-color: white;
      padding: 20px;
      border-radius: 8px;
      width: 90%;
      max-width: 800px;
      max-height: 80vh;
      overflow-y: auto;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.2);
    }
    .config-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 20px;
    }
    .config-header h2 {
      margin: 0;
    }
    .config-close {
      background: none;
      border: none;
      font-size: 24px;
      cursor: pointer;
      color: #888;
    }
    .config-form {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
      gap: 15px 24px;
      align-items: flex-start;
    }
    .form-group {
      display: flex;
      flex-direction: column;
      gap: 5px;
    }
    .form-group label {
      font-weight: bold;
    }
    .form-group input, .form-group select {
      padding: 10px;
      border: 1px solid #ddd;
      border-radius: 4px;
      font-size: 16px;
    }
    .form-group input:focus, .form-group select:focus {
      border-color: #4285f4;
      outline: none;
    }
    .config-submit {
      margin-top: 20px;
      padding: 12px 0;
      background-color: #4285f4;
      color: white;
      border: none;
      border-radius: 25px;
      cursor: pointer;
      font-size: 16px;
      transition: background-color 0.3s;
    }
    .config-submit:hover {
      background-color: #3367d6;
    }
    .bandwidth-note {
      font-size: 12px;
      color: #888;
      margin-top: 5px;
    }
  </style>
</head>
<body>
  <h1>æ™ºèƒ½åŠ©æ‰‹ / AI Assistant / AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ</h1>

  <div class="controls">
    <div class="language-toggle">
      <button id="cantonese-btn" class="toggle-btn active">å»£æ±è©±</button>
      <button id="english-btn" class="toggle-btn">English</button>
      <button id="mandarin-btn" class="toggle-btn">æ™®é€šè©±</button>
      <button id="japanese-btn" class="toggle-btn">æ—¥æœ¬èª</button>
    </div>
    <button id="config-btn" title="Configuration">âš™ï¸</button>
  </div>

  <div class="chat-container" id="chat-container">
    <div class="message-container bot-container">
      <div class="message bot">ä½ å¥½ï¼æˆ‘ä¿‚ä½ å˜…å»£æ±è©±AIåŠ©æ‰‹ï¼Œæœ‰å’©å¯ä»¥å¹«åˆ°ä½ ï¼Ÿ</div>
      <button class="speak-btn" onclick="speakMessage(this.previousElementSibling.textContent)">ğŸ”Š</button>
    </div>
  </div>

  <div class="input-area">
    <input type="text" id="message-input" placeholder="è¼¸å…¥å•é¡Œæˆ–é–‹å§‹äº¤è«‡...">
    <button id="send-btn">ç™¼é€</button>
    <button id="mic-btn" class="mic-button">ğŸ¤</button>
  </div>

  <!-- Configuration Panel -->
  <div id="config-panel" class="config-panel">
    <div class="config-content">
      <div class="config-header">
        <h2>è¨­å®š | Configuration</h2>
        <button class="config-close" onclick="closeConfigPanel()">&times;</button>
      </div>
      <div class="config-form">
        <div class="form-group">
          <label for="license-key">License Key:</label>
          <input type="text" id="license-key" placeholder="è«‹è¼¸å…¥License Key">
        </div>
        <div class="form-group">
          <label for="minimax-group-id">Chat Group ID:</label>
          <input type="text" id="minimax-group-id" placeholder="è«‹è¼¸å…¥Chat Group ID">
        </div>
        <div class="form-group">
          <label for="minimax-api-key">Chat API Key:</label>
          <input type="text" id="minimax-api-key" placeholder="è«‹è¼¸å…¥Chat API Key">
        </div>
        <div class="form-group">
          <label for="minimax-voice-id">Voice ID:</label>
          <select id="minimax-voice-id">
            <option value="">é è¨­ (æ ¹æ“šèªè¨€è‡ªå‹•é¸æ“‡)</option>
            <option value="Cantonese_PlayfulMan">ç²µèª PlayfulMan (ç”·è²)</option>
            <option value="Cantonese_WiselProfessor">ç²µèª WiselProfessor (ç”·è²)</option>
            <option value="Cantonese_KindWoman">ç²µèª KindWoman (å¥³è²)</option>
            <option value="Cantonese_GentleLady">ç²µèª GentleLady (å¥³è²)</option>
            <option value="English_GentleLady">English GentleLady (Female)</option>
            <option value="English_CalmWoman">English CalmWoman (Female)</option>
            <option value="conversational_female_2_v1">English Conversational (Female)</option>
            <option value="English_Trustworth_Man">English Trustworth (Man)</option>
            <option value="English_ManWithDeepVoice">English DeepVoice (Man)</option>
            <option value="Mandarin_GentleLady">æ™®é€šè©± GentleLady (å¥³å£°)</option>
            <option value="Chinese (Mandarin)_Reliable_Executive">æ™®é€šè©± Reliable_Executive (ç”·å£°)</option>
            <option value="Chinese (Mandarin)_News_Anchor">æ™®é€šè©± News_Anchor (å¥³å£°)</option>
            <option value="Chinese (Mandarin)_Unrestrained_Young_Man">æ™®é€šè©± Unrestrained_Young_Man (ç”·å£°)</option>
            <option value="hunyin_6">æ™®é€šè©± Hunyin (ç”·å£°)</option>
            <option value="Chinese (Mandarin)_Soft_Girl">æ™®é€šè©± Soft_Girl (å¥³å£°)</option>
            <option value="Japanese_DecisivePrincess">æ—¥æœ¬èª DecisivePrincess(å¥³æ€§ã®å£°)</option>
            <option value="Japanese_KindLady">æ—¥æœ¬èª KindLady (å¥³æ€§ã®å£°)</option> 
            <option value="Japanese_GentleButler">æ—¥æœ¬èª GentleButler (ç”·æ€§ã®å£°)</option>
          </select>
        </div>
        <div class="form-group">
          <label for="response-type">å›æ‡‰é¡å‹:</label>
          <select id="response-type">
            <option value="audio">èªéŸ³</option>
            <option value="text">æ–‡å­—</option>
            <option value="both">èªéŸ³å’Œæ–‡å­—</option>
          </select>
        </div>
        <div class="form-group">
          <label for="stt-method">èªéŸ³è¾¨è­˜æ–¹æ³•:</label>
          <select id="stt-method">
            <option value="web-speech">ç€è¦½å™¨èªéŸ³è¾¨è­˜ (Web Speech API)</option>
            <option value="minimax">MiniMax èªéŸ³è¾¨è­˜</option>
          </select>
        </div>
        <div class="form-group">
          <label for="speech-rate">èªé€Ÿ:</label>
          <div class="range-container">
            <input type="range" id="speech-rate" min="0.5" max="1.5" step="0.1" value="1.0">
            <span id="speech-rate-value">1.0</span>
          </div>
        </div>
        <div class="form-group">
          <label for="speech-pitch">éŸ³èª¿:</label>
          <div class="range-container">
            <input type="range" id="speech-pitch" min="0.5" max="1.5" step="0.1" value="1.0">
            <span id="speech-pitch-value">1.0</span>
          </div>
        </div>
        <div class="form-group">
          <label for="video-fps">è¦–é »å¹€ç‡:</label>
          <input type="number" id="video-fps" value="1" min="1" max="30">
          <div class="bandwidth-note">æ›´é«˜å¹€ç‡éœ€è¦æ›´å¤šç¶²çµ¡é »å¯¬</div>
        </div>
        <button class="config-submit" onclick="saveConfiguration()">ç¢ºèª</button>
      </div>
    </div>
  </div>

  <div class="footnote">Powered by NTT Comm Asia - LLMs</div>

  <script>
    // DOM Elements
    const chatContainer = document.getElementById('chat-container');
    const messageInput = document.getElementById('message-input');
    const sendBtn = document.getElementById('send-btn');
    const micBtn = document.getElementById('mic-btn');
    const cantoneseBtn = document.getElementById('cantonese-btn');
    const englishBtn = document.getElementById('english-btn');
    const mandarinBtn = document.getElementById('mandarin-btn');
    const japaneseBtn = document.getElementById('japanese-btn');
    const configBtn = document.getElementById('config-btn');
    const configPanel = document.getElementById('config-panel');

    // Configuration Elements
    const licenseKeyInput = document.getElementById('license-key');
    const minimaxGroupIdInput = document.getElementById('minimax-group-id');
    const minimaxApiKeyInput = document.getElementById('minimax-api-key');
    const minimaxVoiceIdInput = document.getElementById('minimax-voice-id');
    const responseTypeSelect = document.getElementById('response-type');
    const sttMethodSelect = document.getElementById('stt-method');
    const speechRateInput = document.getElementById('speech-rate');
    const speechRateValue = document.getElementById('speech-rate-value');
    const speechPitchInput = document.getElementById('speech-pitch');
    const speechPitchValue = document.getElementById('speech-pitch-value');
    const videoFpsInput = document.getElementById('video-fps');

    // State variables
    let currentLanguage = 'cantonese';
    let recognition = null;
    let mediaRecorder = null;
    let isListening = false;

    // Configuration state
    let config = {
      licenseKey: '',
      minimaxGroupId: '',
      minimaxApiKey: '',
      minimaxVoiceId: '',
      responseType: 'audio',
      sttMethod: 'web-speech',
      speechRate: 1.0,
      speechPitch: 1.0,
      videoFps: 1
    };

    // Initialize on page load
    document.addEventListener('DOMContentLoaded', () => {
      loadConfiguration();
      initSpeechRecognition();
      setupEventListeners();
    });

    // Load configuration from localStorage if available
    function loadConfiguration() {
      const savedConfig = localStorage.getItem('voiceBotConfig');
      if (savedConfig) {
        try {
          const parsedConfig = JSON.parse(savedConfig);
          config = { ...config, ...parsedConfig };

          // Apply saved configuration to form
          licenseKeyInput.value = config.licenseKey || '';
          minimaxGroupIdInput.value = config.minimaxGroupId || '';
          minimaxApiKeyInput.value = config.minimaxApiKey || '';
          minimaxVoiceIdInput.value = config.minimaxVoiceId || '';
          responseTypeSelect.value = config.responseType || 'audio';
          sttMethodSelect.value = config.sttMethod || 'web-speech';
          speechRateInput.value = config.speechRate || 1.0;
          speechRateValue.textContent = config.speechRate || 1.0;
          speechPitchInput.value = config.speechPitch || 1.0;
          speechPitchValue.textContent = config.speechPitch || 1.0;
          videoFpsInput.value = config.videoFps || 1;
        } catch (error) {
          console.error('Error loading configuration:', error);
        }
      }
    }

    // Save configuration to localStorage
    function saveConfiguration() {
      config.licenseKey = licenseKeyInput.value;
      config.minimaxGroupId = minimaxGroupIdInput.value;
      config.minimaxApiKey = minimaxApiKeyInput.value;
      config.minimaxVoiceId = minimaxVoiceIdInput.value;
      config.responseType = responseTypeSelect.value;
      config.sttMethod = sttMethodSelect.value;
      config.speechRate = parseFloat(speechRateInput.value) || 1.0;
      config.speechPitch = parseFloat(speechPitchInput.value) || 1.0;
      config.videoFps = parseInt(videoFpsInput.value) || 1;

      localStorage.setItem('voiceBotConfig', JSON.stringify(config));
      closeConfigPanel();

      // Show configuration saved message
      addStatusMessage(currentLanguage === 'cantonese' ?
        'è¨­å®šå·²ä¿å­˜ï¼' :
        currentLanguage === 'mandarin' ?
          'è®¾ç½®å·²ä¿å­˜ï¼' :
          currentLanguage === 'japanese' ?
            'è¨­å®šãŒä¿å­˜ã•ã‚Œã¾ã—ãŸï¼' :
            'Configuration saved!');
    }

    // Show configuration panel
    function showConfigPanel() {
      configPanel.style.display = 'flex';
    }

    // Close configuration panel
    function closeConfigPanel() {
      configPanel.style.display = 'none';
    }

    // Setup event listeners
    function setupEventListeners() {
      // Configuration button click handler
      configBtn.addEventListener('click', showConfigPanel);

      // Send button click handler
      sendBtn.addEventListener('click', () => {
        sendMessage();
      });

      // Enter key press in input field
      messageInput.addEventListener('keypress', (e) => {
        if (e.key === 'Enter') {
          sendMessage();
        }
      });

      // Microphone button click handler
      micBtn.addEventListener('click', toggleListening);

      // Voice ID dropdown change handler - keep config in sync immediately
      minimaxVoiceIdInput.addEventListener('change', () => {
        config.minimaxVoiceId = minimaxVoiceIdInput.value;
        // Persist to localStorage so it survives reloads
        try {
          const savedConfig = localStorage.getItem('voiceBotConfig');
          const baseConfig = savedConfig ? JSON.parse(savedConfig) : {};
          localStorage.setItem('voiceBotConfig', JSON.stringify({ ...baseConfig, minimaxVoiceId: config.minimaxVoiceId }));
        } catch (e) {
          console.error('Error saving Voice ID to localStorage:', e);
        }
      });

      // Language toggle handlers
      cantoneseBtn.addEventListener('click', () => setLanguage('cantonese'));
      englishBtn.addEventListener('click', () => setLanguage('english'));
      mandarinBtn.addEventListener('click', () => setLanguage('mandarin'));
      japaneseBtn.addEventListener('click', () => setLanguage('japanese'));

      // Speech rate slider handler
      speechRateInput.addEventListener('input', () => {
        speechRateValue.textContent = speechRateInput.value;
      });

      // Speech pitch slider handler
      speechPitchInput.addEventListener('input', () => {
        speechPitchValue.textContent = speechPitchInput.value;
      });
    }

    // Set the current language
    function setLanguage(lang) {
      currentLanguage = lang;

      // Reset active state for all language buttons
      cantoneseBtn.classList.remove('active');
      englishBtn.classList.remove('active');
      mandarinBtn.classList.remove('active');
      japaneseBtn.classList.remove('active');

      // Update UI and placeholders based on language
      if (lang === 'cantonese') {
        cantoneseBtn.classList.add('active');
        messageInput.placeholder = 'è¼¸å…¥å•é¡Œæˆ–é–‹å§‹äº¤è«‡...';
        sendBtn.textContent = 'ç™¼é€';
      } else if (lang === 'english') {
        englishBtn.classList.add('active');
        messageInput.placeholder = 'Type a message or start talking...';
        sendBtn.textContent = 'Send';
      } else if (lang === 'mandarin') {
        mandarinBtn.classList.add('active');
        messageInput.placeholder = 'è¾“å…¥é—®é¢˜æˆ–å¼€å§‹äº¤è°ˆ...';
        sendBtn.textContent = 'å‘é€';
      } else if (lang === 'japanese') {
        japaneseBtn.classList.add('active');
        messageInput.placeholder = 'ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã™ã‚‹ã‹ã€è©±ã—å§‹ã‚ã¦ãã ã•ã„...';
        sendBtn.textContent = 'é€ä¿¡';
      }

      // Update speech recognition language
      if (recognition) {
        if (lang === 'cantonese') {
          recognition.lang = 'zh-HK';
        } else if (lang === 'english') {
          recognition.lang = 'en-US';
        } else if (lang === 'mandarin') {
          recognition.lang = 'zh-CN';
        } else if (lang === 'japanese') {
          recognition.lang = 'ja-JP';
        }
      }
    }

    // Add a message to the chat
    function addMessage(text, isUser = false) {
      const container = document.createElement('div');
      container.className = isUser ? 'message-container user-container' : 'message-container bot-container';

      const messageDiv = document.createElement('div');
      messageDiv.className = isUser ? 'message user' : 'message bot';
      messageDiv.textContent = text;
      container.appendChild(messageDiv);

      // Add speak button for bot messages if audio responses are enabled
      if (!isUser && (config.responseType === 'audio' || config.responseType === 'both')) {
        const speakBtn = document.createElement('button');
        speakBtn.className = 'speak-btn';
        speakBtn.textContent = 'ğŸ”Š';
        speakBtn.onclick = () => speakMessage(text);
        container.appendChild(speakBtn);
      }

      chatContainer.appendChild(container);
      chatContainer.scrollTop = chatContainer.scrollHeight;

      // Auto-speak bot messages if audio responses are enabled
      if (!isUser && (config.responseType === 'audio' || config.responseType === 'both')) {
        speakMessage(text);
      }

      return messageDiv;
    }

    // Add a status message
    function addStatusMessage(text) {
      const statusDiv = document.createElement('div');
      statusDiv.className = 'status-message';
      statusDiv.textContent = text;
      chatContainer.appendChild(statusDiv);
      chatContainer.scrollTop = chatContainer.scrollHeight;

      // Auto-remove status message after 5 seconds
      setTimeout(() => {
        try {
          chatContainer.removeChild(statusDiv);
        } catch (err) {
          // Element might already be removed
        }
      }, 5000);

      return statusDiv;
    }

    // Initialize speech recognition
    function initSpeechRecognition() {
      // Check if browser supports SpeechRecognition
      if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        addStatusMessage(currentLanguage === 'cantonese' ?
          'ä½ å€‹ç€è¦½å™¨å””æ”¯æ´èªéŸ³è¾¨è­˜åŠŸèƒ½ï¼Œè«‹ç”¨Chromeç€è¦½å™¨ã€‚' :
          currentLanguage === 'mandarin' ?
            'ä½ çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨Chromeæµè§ˆå™¨ã€‚' :
            currentLanguage === 'japanese' ?
              'ã‚ãªãŸã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚Chromeãƒ–ãƒ©ã‚¦ã‚¶ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚' :
              'Your browser does not support speech recognition. Please use Chrome.');
        return;
      }

      // Create speech recognition instance
      window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new window.SpeechRecognition();

      // Configure recognition
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = currentLanguage === 'cantonese' ? 'zh-HK' :
        currentLanguage === 'english' ? 'en-US' :
        currentLanguage === 'mandarin' ? 'zh-CN' :
        'ja-JP';

      // Handle recognition results
      recognition.onresult = function(event) {
        const transcript = event.results[0][0].transcript;
        messageInput.value = transcript;
        sendMessage();
      };

      // Handle errors
      recognition.onerror = function(event) {
        micBtn.classList.remove('recording');
        isListening = false;

        let errorMessage = '';
        if (event.error === 'no-speech') {
          errorMessage = currentLanguage === 'cantonese' ?
            'è½å””åˆ°ä½ æŠŠè²ï¼Œè«‹å†è©¦éã€‚' :
            currentLanguage === 'mandarin' ?
              'æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·å†è¯•ä¸€æ¬¡ã€‚' :
              currentLanguage === 'japanese' ?
                'éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚' :
                'No speech detected. Please try again.';
        } else if (event.error === 'audio-capture') {
          errorMessage = currentLanguage === 'cantonese' ?
            'æŠ“å””åˆ°éº¥å…‹é¢¨ï¼Œéº»ç…©æª¢æŸ¥ä¸‹ä½ å˜…è£ç½®è¨­å®šã€‚' :
            currentLanguage === 'mandarin' ?
              'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥è®¾å¤‡è®¾ç½®ã€‚' :
              currentLanguage === 'japanese' ?
                'ãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚ãƒ‡ãƒã‚¤ã‚¹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚' :
                'No microphone detected. Please check your device settings.';
        } else if (event.error === 'not-allowed') {
          errorMessage = currentLanguage === 'cantonese' ?
            'éº¥å…‹é¢¨ä½¿ç”¨æ¬Šé™è¢«æ‹’çµ•ï¼Œè«‹å…è¨±å­˜å–éº¥å…‹é¢¨ã€‚' :
            currentLanguage === 'mandarin' ?
              'éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·å…è®¸è®¿é—®éº¦å…‹é£ã€‚' :
              currentLanguage === 'japanese' ?
                'ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚' :
                'Microphone permission denied. Please allow access to your microphone.';
        } else {
          errorMessage = currentLanguage === 'cantonese' ?
            'èªéŸ³è¾¨è­˜éŒ¯èª¤ï¼š' + event.error :
            currentLanguage === 'mandarin' ?
              'è¯­éŸ³è¯†åˆ«é”™è¯¯ï¼š' + event.error :
              currentLanguage === 'japanese' ?
                'éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼ï¼š' + event.error :
                'Speech recognition error: ' + event.error;
        }

        addStatusMessage(errorMessage);
      };

      // Handle recognition end
      recognition.onend = function() {
        micBtn.classList.remove('recording');
        isListening = false;
      };
    }

    // Toggle listening state
    async function toggleListening() {
      if (isListening) {
        // Stop listening
        if (config.sttMethod === 'web-speech' && recognition) {
          recognition.stop();
        } else if (config.sttMethod === 'minimax' && mediaRecorder) {
          mediaRecorder.stop();
        }
        micBtn.classList.remove('recording');
        isListening = false;
      } else {
        // Start listening
        if (config.sttMethod === 'web-speech') {
          if (!recognition) {
            initSpeechRecognition();
          }

          try {
            recognition.start();
            micBtn.classList.add('recording');
            isListening = true;

            // Show status message
            const statusMessage = currentLanguage === 'cantonese' ?
              'æˆ‘è½ç·Šï¼Œè¬›å•¦...' :
              currentLanguage === 'mandarin' ?
                'æˆ‘åœ¨å¬ï¼Œè¯·è¯´...' :
                currentLanguage === 'japanese' ?
                  'èã„ã¦ã„ã¾ã™ã€‚ã©ã†ãè©±ã—ã¦ãã ã•ã„â€¦' :
                  'Listening...';
            addStatusMessage(statusMessage);
          } catch (err) {
            console.error('Speech recognition error:', err);
            const errorMessage = currentLanguage === 'cantonese' ?
              'èªéŸ³è¾¨è­˜å•Ÿå‹•å¤±æ•—ï¼Œè«‹é‡æ–°æ•´ç†é é¢å†è©¦ã€‚' :
              currentLanguage === 'mandarin' ?
                'è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢åé‡è¯•ã€‚' :
                currentLanguage === 'japanese' ?
                  'éŸ³å£°èªè­˜ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚' :
                  'Failed to start speech recognition. Please refresh the page and try again.';
            addStatusMessage(errorMessage);
          }
        } else if (config.sttMethod === 'minimax') {
          try {
            // Request microphone access
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);

            const audioChunks = [];

            mediaRecorder.ondataavailable = (event) => {
              audioChunks.push(event.data);
            };

            mediaRecorder.onstop = async () => {
              const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
              await processMinimaxSTT(audioBlob);
              // Stop all tracks to release microphone
              stream.getTracks().forEach(track => track.stop());
            };

            mediaRecorder.start();
            micBtn.classList.add('recording');
            isListening = true;

            // Show status message
            const statusMessage = currentLanguage === 'cantonese' ?
              'æˆ‘è½ç·Šï¼Œè¬›å•¦...' :
              'Listening...';
            addStatusMessage(statusMessage);

            // Auto-stop after 10 seconds
            setTimeout(() => {
              if (isListening && mediaRecorder) {
                mediaRecorder.stop();
              }
            }, 10000);

          } catch (err) {
            console.error('MediaRecorder error:', err);
            const errorMessage = currentLanguage === 'cantonese' ?
              'éº¥å…‹é¢¨å­˜å–å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¬Šé™ã€‚' :
              currentLanguage === 'mandarin' ?
                'éº¦å…‹é£è®¿é—®å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™ã€‚' :
                currentLanguage === 'japanese' ?
                  'ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚' :
                  'Microphone access failed. Please check permissions.';
            addStatusMessage(errorMessage);
          }
        }
      }
    }

    // Speak message using Minimax TTS API
    async function speakMessage(text) {
      try {
        // Check if API key is configured
        if (!config.licenseKey) {
          addStatusMessage(currentLanguage === 'cantonese' ?
            'éœ€è¦é˜¿é‡Œé›²APIå¯†é‘°ã€‚è«‹é»æ“Šâš™ï¸è¨­å®šå¯†é‘°ã€‚' :
            currentLanguage === 'mandarin' ?
              'éœ€è¦é˜¿é‡Œäº‘ API å¯†é’¥ã€‚è¯·ç‚¹å‡»âš™ï¸è¿›è¡Œè®¾ç½®ã€‚' :
              currentLanguage === 'japanese' ?
                'Alibaba Cloud ã® API ã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚âš™ï¸ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è¨­å®šã—ã¦ãã ã•ã„ã€‚' :
                'Alibaba Cloud API key required. Please click âš™ï¸ to configure.');
          return;
        }

        // Show speaking status
        const statusMessage = addStatusMessage(currentLanguage === 'cantonese' ?
          'ç”ŸæˆèªéŸ³ä¸­...' :
          currentLanguage === 'mandarin' ?
            'æ­£åœ¨ç”Ÿæˆè¯­éŸ³â€¦' :
            currentLanguage === 'japanese' ?
              'éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™â€¦' :
              'Generating speech...');

        // Fetch audio from TTS API
        const response = await fetch('/api/tts', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'X-License-Key': config.licenseKey,
            'X-Minimax-Group-Id': config.minimaxGroupId,
            'X-Minimax-Api-Key': config.minimaxApiKey
          },
          body: JSON.stringify({
            text: text,
            language: currentLanguage,
            // Use the current dropdown value directly so changes apply immediately
            minimaxVoiceId: minimaxVoiceIdInput.value
          })
        });

        // Remove status message
        try {
          chatContainer.removeChild(statusMessage);
        } catch (err) {
          // Message might already be removed
        }

        if (!response.ok) {
          const errorData = await response.json();
          addStatusMessage(errorData.error || (currentLanguage === 'cantonese' ?
            'èªéŸ³ç”Ÿæˆå¤±æ•—' :
            currentLanguage === 'mandarin' ?
              'è¯­éŸ³ç”Ÿæˆå¤±è´¥' :
              currentLanguage === 'japanese' ?
                'éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ' :
                'Speech generation failed'));
          return;
        }

        // Create audio blob and play
        const audioBlob = await response.blob();
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);

        // Play the audio
        audio.play();

        // Clean up the URL after playing
        audio.onended = () => {
          URL.revokeObjectURL(audioUrl);
        };

      } catch (error) {
        console.error('Error in speakMessage:', error);
        addStatusMessage(currentLanguage === 'cantonese' ?
          'èªéŸ³æ’­æ”¾éŒ¯èª¤' :
          currentLanguage === 'mandarin' ?
            'è¯­éŸ³æ’­æ”¾é”™è¯¯' :
            currentLanguage === 'japanese' ?
              'éŸ³å£°ã®å†ç”Ÿä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ' :
              'Speech playback error');
      }
    }

    // Send message to API and display response
    async function sendMessage() {
      const messageText = messageInput.value.trim();
      if (!messageText) return;

      // Add user message to chat
      addMessage(messageText, true);
      messageInput.value = '';

      // Show typing indicator
      const statusMessage = addStatusMessage(currentLanguage === 'cantonese' ?
        'æ€è€ƒç·Š...' :
        currentLanguage === 'mandarin' ?
          'æ€è€ƒä¸­â€¦' :
          currentLanguage === 'japanese' ?
            'è€ƒãˆä¸­â€¦' :
            'Thinking...');

      try {
        // Check if API key is configured
        if (!config.licenseKey) {
          throw new Error(currentLanguage === 'cantonese' ?
            'éœ€è¦é˜¿é‡Œé›²APIå¯†é‘°ã€‚è«‹é»æ“Šâš™ï¸è¨­å®šå¯†é‘°ã€‚' :
            currentLanguage === 'mandarin' ?
              'éœ€è¦é˜¿é‡Œäº‘ API å¯†é’¥ã€‚è¯·ç‚¹å‡»âš™ï¸è¿›è¡Œè®¾ç½®ã€‚' :
              currentLanguage === 'japanese' ?
                'Alibaba Cloud ã® API ã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚âš™ï¸ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è¨­å®šã—ã¦ãã ã•ã„ã€‚' :
                'Alibaba Cloud API key required. Please click âš™ï¸ to configure.');
        }

        // Prepare API request
        const response = await fetch('/api/chat', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'X-License-Key': config.licenseKey
          },
          body: JSON.stringify({
            message: messageText,
            language: currentLanguage
          })
        });

        // Check for errors
        if (!response.ok) {
          throw new Error(
            currentLanguage === 'cantonese' ?
              'APIéŒ¯èª¤ï¼š' + response.status + ' ' + response.statusText :
              currentLanguage === 'mandarin' ?
                'API é”™è¯¯ï¼š' + response.status + ' ' + response.statusText :
                currentLanguage === 'japanese' ?
                  'API ã‚¨ãƒ©ãƒ¼ï¼š' + response.status + ' ' + response.statusText :
                  'API error: ' + response.status + ' ' + response.statusText
          );
        }

        // Parse response
        const data = await response.json();

        // Remove typing indicator
        try {
          chatContainer.removeChild(statusMessage);
        } catch (err) {
          // Message might already be removed
        }

        // Add bot response to chat
        if (data.response) {
          addMessage(data.response, false);
        } else {
          throw new Error(currentLanguage === 'cantonese' ?
            'æ”¶åˆ°ç©ºå˜…å›æ‡‰ï¼Œè«‹å†è©¦ã€‚' :
            currentLanguage === 'mandarin' ?
              'æ”¶åˆ°ç©ºçš„å“åº”ï¼Œè¯·é‡è¯•ã€‚' :
              currentLanguage === 'japanese' ?
                'ç©ºã®å¿œç­”ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚' :
                'Received empty response. Please try again.');
        }
      } catch (error) {
        console.error('Error:', error);

        // Remove typing indicator
        try {
          chatContainer.removeChild(statusMessage);
        } catch (err) {
          // Message might already be removed
        }

        // Show error message
        addStatusMessage(error.message || (currentLanguage === 'cantonese' ?
          'ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ã€‚' :
          currentLanguage === 'mandarin' ?
            'å‘ç”Ÿé”™è¯¯ï¼Œè¯·é‡è¯•ã€‚' :
            currentLanguage === 'japanese' ?
              'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚' :
              'An error occurred. Please try again.'));
      }
    }

    // Process MiniMax STT
    async function processMinimaxSTT(audioBlob) {
      try {
        // Show processing status
        const statusMessage = addStatusMessage(currentLanguage === 'cantonese' ?
          'è™•ç†èªéŸ³ä¸­...' :
          currentLanguage === 'mandarin' ?
            'æ­£åœ¨å¤„ç†è¯­éŸ³â€¦' :
            currentLanguage === 'japanese' ?
              'éŸ³å£°ã‚’å‡¦ç†ã—ã¦ã„ã¾ã™â€¦' :
              'Processing speech...');

        // Create FormData to send audio
        const formData = new FormData();
        formData.append('audio', audioBlob, 'recording.wav');
        formData.append('language', currentLanguage);

        // Send to STT API
        const response = await fetch('/api/stt', {
          method: 'POST',
          headers: {
            'X-Minimax-Group-Id': config.minimaxGroupId,
            'X-Minimax-Api-Key': config.minimaxApiKey
          },
          body: formData
        });

        // Remove status message
        try {
          chatContainer.removeChild(statusMessage);
        } catch (err) {
          // Message might already be removed
        }

        if (!response.ok) {
          const errorData = await response.json();
          addStatusMessage(errorData.error || (currentLanguage === 'cantonese' ?
            'èªéŸ³è¾¨è­˜å¤±æ•—' :
            currentLanguage === 'mandarin' ?
              'è¯­éŸ³è¯†åˆ«å¤±è´¥' :
              currentLanguage === 'japanese' ?
                'éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸ' :
                'Speech recognition failed'));
          return;
        }

        // Parse response
        const data = await response.json();
        if (data.text) {
          messageInput.value = data.text;
          sendMessage();
        } else {
          addStatusMessage(currentLanguage === 'cantonese' ?
            'æœªè­˜åˆ¥åˆ°èªéŸ³' :
            currentLanguage === 'mandarin' ?
              'æœªè¯†åˆ«åˆ°è¯­éŸ³' :
              currentLanguage === 'japanese' ?
                'éŸ³å£°ãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ' :
                'No speech recognized');
        }
      } catch (error) {
        console.error('Error in processMinimaxSTT:', error);
        addStatusMessage(currentLanguage === 'cantonese' ?
          'èªéŸ³è™•ç†éŒ¯èª¤' :
          currentLanguage === 'mandarin' ?
            'è¯­éŸ³å¤„ç†é”™è¯¯' :
            currentLanguage === 'japanese' ?
              'éŸ³å£°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ' :
              'Speech processing error');
      }
    }

    // Load voices when available (for Safari and other browsers that load voices asynchronously)
    if ('speechSynthesis' in window) {
      // Chrome loads voices synchronously
      window.speechSynthesis.getVoices();

      // Safari and some other browsers load voices asynchronously
      window.speechSynthesis.onvoiceschanged = () => {
        window.speechSynthesis.getVoices();
      };
    }
  </script>
</body>
</html>